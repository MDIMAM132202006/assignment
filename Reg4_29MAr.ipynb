{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ebea53-eb85-47e8-bf5b-6c6faadc4e16",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "ans:  Lasso Regression, short for Least Absolute Shrinkage and Selection Operator Regression, is a linear regression technique used for both prediction and feature selection. It differs from other regression techniques, such as simple linear regression and ridge regression, by introducing a regularization term that penalizes the absolute values of the regression coefficients. This penalty encourages the model to set some of the coefficients to zero, effectively performing feature selection and producing a simpler, more interpretable model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eabf235-dd43-4512-97dc-401782d44f37",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "ans: The main advantage of using Lasso Regression for feature selection is its ability to automatically identify and select a subset of the most important features from a larger set of input variables. By setting some coefficients to zero, it helps reduce overfitting and simplifies the model while maintaining good predictive performance. This can be especially valuable when dealing with high-dimensional datasets with many potentially irrelevant or redundant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05feeb5a-cdf6-4463-bf1a-5956507e0b2b",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "ans:\n",
    "1. Coefficients with non-zero values represent features that are selected by the model as relevant for prediction.\n",
    "\n",
    "2. Coefficients with zero values correspond to features that the model has effectively removed from the regression equation, indicating they are not contributing to the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4e5a7-4483-4b31-b0fe-14cc4051f877",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?\n",
    "\n",
    "ans: \n",
    "In Lasso Regression, the main tuning parameter is lambda (Î»), which controls the strength of the regularization penalty. Increasing lambda results in stronger regularization and more coefficients being pushed towards zero. The tuning parameter can be adjusted to find the right balance between model complexity and accuracy. Cross-validation techniques can help identify the optimal value of lambda for a specific dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6a7af-2eae-4106-9f0f-41fbde86a059",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "ans: Lasso Regression is primarily used for linear regression problems. It is not suitable for handling non-linear relationships between the features and the target variable. For non-linear regression problems, techniques like polynomial regression or non-linear models, such as decision trees or support vector machines, are more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d803a28-cc58-4e22-97bf-ccf588627bfe",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "ans: The main difference between Ridge Regression and Lasso Regression is the type of regularization they apply:\n",
    "\n",
    "1.Ridge Regression uses L2 regularization, which penalizes the sum of squared coefficients, encouraging coefficients to be small but not exactly zero.\n",
    "\n",
    "2.Lasso Regression uses L1 regularization, which penalizes the absolute values of coefficients, promoting some coefficients to be exactly zero, effectively performing feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4273bd7-ea93-42f8-9052-cb8210adf884",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "ans:  Lasso Regression can handle multicollinearity to some extent by automatically selecting a subset of features. When multicollinearity exists among correlated features, Lasso may choose one of them and set the others to zero. However, it's not a perfect solution for multicollinearity, and it's generally recommended to preprocess the data to address multicollinearity before applying Lasso Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3752abaa-8e75-4627-9d83-ad2f3148a43d",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    "ans: To choose the optimal value of the regularization parameter (lambda) in Lasso Regression, you can use cross-validation techniques. You can train the model with different values of lambda and evaluate its performance using a validation dataset. The lambda value that results in the best model performance (e.g., lowest mean squared error) on the validation set is the optimal choice. This process can be automated by performing a grid search or using more advanced optimization techniques like coordinate descent or gradient-based methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63789e3b-2823-4a6c-b5c4-482cc2e4a455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
